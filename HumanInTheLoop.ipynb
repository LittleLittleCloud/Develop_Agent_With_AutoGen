{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human in the loop\n",
    "\n",
    "In the previous notebook, we created an assistant agent that can send hello-world message using LLM.\n",
    "\n",
    "In this notebook, we will further introduce human in the loop to have conversation with that assistant agent. To do that, we are going to add another user agent that can take input from user and send it to the assistant agent. We also need to preserve the previous conversation history to make the conversation more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyuz\\AppData\\Local\\Temp\\ipykernel_112972\\1610075179.py:15: FutureWarning: OpenAIChatCompletionClient moved to autogen_ext. Please import it from autogen_ext.modelsChatCompletionClient.\n",
      "  from autogen_core.components.models import OpenAIChatCompletionClient\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "from autogen_core.base import MessageContext, AgentId, AgentInstantiationContext, TopicId\n",
    "from autogen_core.components import DefaultTopicId, RoutedAgent, default_subscription, message_handler, TypeSubscription\n",
    "from autogen_core.components.code_executor import CodeExecutor, extract_markdown_code_blocks\n",
    "from autogen_core.components.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "import tempfile\n",
    "from autogen_core.components.tool_agent import ToolAgent, tool_agent_caller_loop\n",
    "from autogen_core.application import SingleThreadedAgentRuntime\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient\n",
    "import random\n",
    "\n",
    "from autogen_core.base import CancellationToken\n",
    "from autogen_core.components.tools import FunctionTool, ToolSchema\n",
    "from autogen_core.components._image import Image\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import uuid;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message Contract\n",
    "\n",
    "Here we introduce two contracts\n",
    "- Message: the same one as in the previous notebook\n",
    "- Conversation: the chat history\n",
    "\n",
    "## Why we introduce Conversation contract?\n",
    "The `Conversation` will save all chat history between the user and the assistant agent to provide context for assistant agent to generate more meaningful responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    text: str\n",
    "    source: Optional[str] = None\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    chat_history: List[Message]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UserAgent\n",
    "We first define the UserAgent class, which represents the human user in the conversation.\n",
    "\n",
    "The UserAgent handles Conversation in the following way. When it receives a conversation, it first prompts the user for a response.\n",
    "If user says `TERMINATE`, the conversation is terminated. Otherwise, the user's response is added to the conversation and publish to agent runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserAgent(RoutedAgent):\n",
    "    def __init__(self, description: str, assistant_topic_type: str) -> None:\n",
    "        super().__init__(description=description)\n",
    "        self._assistant_topic_type = assistant_topic_type\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_request_to_speak(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        # We don't need to respond when the last message is from the user\n",
    "        if len(message.chat_history) > 0 and message.chat_history[-1].source == self.type:\n",
    "            return\n",
    "        user_input = input(\"Enter your message, type 'TERMINATE' to terminate the task: \")\n",
    "        print(f\"### User: \\n{user_input}\")\n",
    "        if user_input == \"TERMINATE\": # end the conversation\n",
    "            return\n",
    "        \n",
    "        message.chat_history.append(Message(text=user_input, source=self.type))\n",
    "        await self.publish_message(\n",
    "            message,\n",
    "            DefaultTopicId(type=self._assistant_topic_type),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant\n",
    "\n",
    "The Assistant class is the agent that interacts with the user. It receives the conversation from the UserAgent, then uses LLM to generate a response. The response is then added to the conversation and published to the UserAgent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant(RoutedAgent):\n",
    "    def __init__(self,\n",
    "                 model_client: ChatCompletionClient,\n",
    "                 system_message: str = \"You are a helpful AI assistant.\",\n",
    "                 user_topic_type: str = \"user\") -> None:\n",
    "        super().__init__(\"An assistant agent.\")\n",
    "        self._model_client = model_client\n",
    "        self._system_message = system_message\n",
    "        self._user_topic_type = user_topic_type\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        chat_history: List[LLMMessage] = [SystemMessage(content=self._system_message)]\n",
    "        last_message_source = message.chat_history[-1].source if len(message.chat_history) > 0 else self._user_topic_type\n",
    "        for msg in message.chat_history:\n",
    "            if msg.source == self.type:\n",
    "                chat_history.append(AssistantMessage(content=msg.text, source=\"assistant\"))\n",
    "            elif msg.source == self._user_topic_type:\n",
    "                chat_history.append(UserMessage(content=msg.text, source=\"user\"))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown message source: {msg.source}\")\n",
    "            \n",
    "        result = await self._model_client.create(chat_history)\n",
    "        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n",
    "        message.chat_history.append(Message(text=result.content, source=self.type))\n",
    "        await self.publish_message(message, topic_id=DefaultTopicId(type=last_message_source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create runtime and add user, assistant agent to the runtime\n",
    "\n",
    "## What does `add_subscription` do?\n",
    "`add_subscription` tells agent runtime how to deliver messages to the agent based on the message's topic type.\n",
    "In the following code\n",
    "```python\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"user\", user_agent_type.type))\n",
    "```\n",
    "\n",
    "The runtime will deliver messages with topic type `user` to the UserAgent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "How can I assist you today?\n",
      "### User: \n",
      "My name is Geno, how are you\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "Hello, Geno! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "### User: \n",
      "Tell a joke\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "Sure! Hereâ€™s one for you:\n",
      "\n",
      "Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field! \n",
      "\n",
      "Hope that brought a smile! Want to hear another one?\n",
      "### User: \n",
      "which one is larger, 9.9 or 9.11\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "9.11 is larger than 9.9. The decimal 11 is greater than the decimal 9, so 9.11 > 9.9.\n",
      "### User: \n",
      "summarize conversation\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "In our conversation, you introduced yourself as Geno and asked how I was doing. I responded that I'm here to help. Then, you requested a joke, and I shared one about a scarecrow. Finally, you asked which number is larger between 9.9 and 9.11, and I confirmed that 9.11 is larger.\n",
      "### User: \n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "user_agent_type = await UserAgent.register(\n",
    "    runtime,\n",
    "    type=\"user\",\n",
    "    factory=lambda: UserAgent(\n",
    "        description=\"A user agent that generates messages for the assistant agent.\",\n",
    "        assistant_topic_type=\"assistant\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "assistant_agent_type = await Assistant.register(\n",
    "    runtime,\n",
    "    type=\"assistant\",\n",
    "    factory=lambda: Assistant(\n",
    "        model_client=OpenAIChatCompletionClient(\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            model=\"gpt-4o-mini\"\n",
    "        ),\n",
    "        user_topic_type=\"user\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"user\", user_agent_type.type))\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"assistant\", assistant_agent_type.type))\n",
    "\n",
    "runtime.start()\n",
    "session_id = str(uuid.uuid4())\n",
    "msg = Conversation(chat_history=[])\n",
    "await runtime.publish_message(\n",
    "    msg,\n",
    "    TopicId(type=\"assistant\", source=session_id),\n",
    ")\n",
    "await runtime.stop_when_idle()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we learn\n",
    "- How to preserve conversation history by creating a new contract `Conversation`\n",
    "- How to create a UserAgent and take input from user\n",
    "- How to start a conversation between user and assistant agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
