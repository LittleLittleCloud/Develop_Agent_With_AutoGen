{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Agent GroupChat\n",
    "In the previous four notebooks, we have explored and learn how to\n",
    "- create `Assistant` agent to generate hello world responses.\n",
    "- create `WeatherAssistant` agent to provide weather information using the tool call.\n",
    "- create `ImageAssistant` agent to provide information of the image using multi-modal model.\n",
    "- Introduce human user in the conversation.\n",
    "\n",
    "In this notebook, we will create a group chat that hosts all the agents we created in the previous examples, orchestrated by a `GroupChatManager` agent which will manage the conversation flow based on the conversation context.\n",
    "\n",
    "### The topology of the agent group.\n",
    "\n",
    "The group chat will have a star topology where the `GroupChatManager` agent is the central agent that interacts with all the other agents. The `GroupChatManager` agent will interact with the `Assistant`, `WeatherAssistant`, `ImageAssistant`, and `HumanUser` agents. But the `Assistant`, `WeatherAssistant`, and `ImageAssistant` agents will not interact with each other directly.\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[GroupChatManager] <--> B[Assistant]\n",
    "    A[GroupChatManager] <--> C[WeatherAssistant]\n",
    "    A[GroupChatManager] <--> D[ImageAssistant]\n",
    "    A[GroupChatManager] <--> E[HumanUser]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyuz\\AppData\\Local\\Temp\\ipykernel_78704\\387540812.py:19: FutureWarning: OpenAIChatCompletionClient moved to autogen_ext. Please import it from autogen_ext.modelsChatCompletionClient.\n",
      "  from autogen_core.components.models import OpenAIChatCompletionClient, FunctionExecutionResultMessage, FunctionExecutionResult\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from autogen_core.base import MessageContext, AgentId, AgentInstantiationContext, TopicId\n",
    "from autogen_core.components import DefaultTopicId, RoutedAgent, default_subscription, message_handler, TypeSubscription\n",
    "from autogen_core.components.code_executor import CodeExecutor, extract_markdown_code_blocks\n",
    "from autogen_core.components.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "import datetime\n",
    "import tempfile\n",
    "from autogen_core.components.tool_agent import ToolAgent, tool_agent_caller_loop\n",
    "from autogen_core.application import SingleThreadedAgentRuntime\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient, FunctionExecutionResultMessage, FunctionExecutionResult\n",
    "import random\n",
    "import json\n",
    "from autogen_core.base import CancellationToken\n",
    "from autogen_core.components.tools import FunctionTool, ToolSchema\n",
    "from autogen_core.components._image import Image\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import requests\n",
    "import uuid;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    text: str\n",
    "    source: Optional[str] = None\n",
    "    image_url: Optional[str] = None # url or base64 encoded image\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    chat_history: List[Message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserAgent(RoutedAgent):\n",
    "    def __init__(self, description: str, group_manager_topic: str) -> None:\n",
    "        super().__init__(description=description)\n",
    "        self._group_manager_topic = group_manager_topic\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_request_to_speak(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        user_input = input(\"Enter your message, type 'TERMINATE' to terminate the task: \")\n",
    "        print(f\"### User: \\n{user_input}\")\n",
    "        if user_input == \"TERMINATE\": # end the conversation\n",
    "            return\n",
    "        \n",
    "        message.chat_history.append(Message(text=user_input, source=self.type))\n",
    "        await self.publish_message(\n",
    "            message,\n",
    "            DefaultTopicId(type=self._group_manager_topic),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageAssistant(RoutedAgent):\n",
    "    def __init__(self,\n",
    "                 model_client: ChatCompletionClient,\n",
    "                 system_message: str,\n",
    "                 group_manager_topic: str) -> None:\n",
    "        super().__init__(description=system_message)\n",
    "        self._system_message = system_message\n",
    "        self._group_manager_topic = group_manager_topic\n",
    "        self._model_client = model_client\n",
    "        self._load_local_image_tool = FunctionTool(self.load_local_image, description=\"Load local image from disk and return base64 encoded image\")\n",
    "        self._load_image_from_url_tool = FunctionTool(self.load_image_from_url, description=\"Load image from url and return base64 encoded image\")\n",
    "        self._tools = [self._load_local_image_tool, self._load_image_from_url_tool]\n",
    "\n",
    "    # load local image from disk and return base64 encoded image\n",
    "    async def load_local_image(self, path: str) -> str:\n",
    "        with open(path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    async def load_image_from_url(self, url: str) -> str:\n",
    "        return base64.b64encode(requests.get(url).content).decode('utf-8')\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_request_to_speak(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        chat_history: List[LLMMessage] = [SystemMessage(content=self._system_message)]\n",
    "        last_msg = message.chat_history[-1]\n",
    "\n",
    "        # firstly, try to infer if there is an image url or image path in the last message\n",
    "        # e.g. Please describe this local image: /path/to/image.jpg\n",
    "        load_image_prompt = \"\"\"\n",
    "        call the right tool to load the image if there is an image path or url in the last message,\n",
    "        otherwise, say 'No image in the last message'\n",
    "\"\"\"\n",
    "        completion = await self._model_client.create(\n",
    "            [SystemMessage(content=load_image_prompt), UserMessage([last_msg.text], source='user')],\n",
    "            tools=self._tools,\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        if completion.content == \"No image in the last message\":\n",
    "            reply = Message(text=\"No image in the last message\", source=self.type)\n",
    "            message.chat_history.append(reply)\n",
    "            await self.publish_message(\n",
    "                message,\n",
    "                DefaultTopicId(type=self._group_manager_topic),\n",
    "            )\n",
    "            return\n",
    "        \n",
    "        user_message_parts : List[str | Image] = [last_msg.text]\n",
    "\n",
    "        for tool_call in completion.content:\n",
    "            arguments = tool_call.arguments\n",
    "            arguments = json.loads(tool_call.arguments)\n",
    "            if tool_call.name == self._load_local_image_tool.name:\n",
    "                base64_image =  await self._load_local_image_tool.run_json(arguments, ctx.cancellation_token)\n",
    "                user_message_parts.append(Image.from_base64(self._load_local_image_tool.return_value_as_string(base64_image)))\n",
    "            elif tool_call.name == self._load_image_from_url_tool:\n",
    "                base64_image =  await self._load_local_image_tool.run_json(arguments, ctx.cancellation_token)\n",
    "                user_message_parts.append(Image.from_base64(self._load_image_from_url_tool.return_value_as_string(base64_image)))\n",
    "\n",
    "        userMessage = UserMessage(user_message_parts, source='user')\n",
    "        chat_history.append(userMessage)\n",
    "        completion = await self._model_client.create(chat_history)\n",
    "        response = completion.content\n",
    "        if not isinstance(response, str):\n",
    "            raise ValueError(f\"Expected response to be a string, got {response}\")\n",
    "\n",
    "        print(f\"### {self.type}: \\n{response}\")\n",
    "        reply = Message(text=response, source=self.type)\n",
    "        message.chat_history.append(reply)\n",
    "        await self.publish_message(\n",
    "            message,\n",
    "            DefaultTopicId(type=self._group_manager_topic),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherAssistant(RoutedAgent):\n",
    "    def __init__(self,\n",
    "                 model_client: ChatCompletionClient,\n",
    "                 system_message: str,\n",
    "                 group_manager_topic: str) -> None:\n",
    "        super().__init__(description=system_message)\n",
    "        self._system_message = system_message\n",
    "        self._group_manager_topic = group_manager_topic\n",
    "        self._model_client = model_client\n",
    "        self._get_date_tool = FunctionTool(self.get_date, description=\"Get the current date.\")\n",
    "        self._get_weather_tool = FunctionTool(self.get_weather, description=\"Get the weather for a city and state on a given date.\")\n",
    "        self._tools = [self._get_weather_tool, self._get_date_tool]\n",
    "\n",
    "    async def get_weather(self, city: str, state: str, date: str) -> str: # is the return type matter here?\n",
    "    # get the weather for a city and state\n",
    "        print(f\"Getting the weather for {city}, {state} on {date}\")\n",
    "        return f\"The weather in {city}, {state} on {date} will be sunny.\"\n",
    "    \n",
    "    async def get_date(self) -> str:\n",
    "        today = datetime.datetime.today()\n",
    "        return f\"today is {today.strftime('%Y-%m-%d')}\"\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_request_to_speak(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        chat_history: List[LLMMessage] = [SystemMessage(content=self._system_message)]\n",
    "        last_msg = message.chat_history[-1]\n",
    "        if last_msg.image_url is not None:\n",
    "            reply = Message(text=\"can't recognize image in the last message\", source=self.type)\n",
    "            message.chat_history.append(reply)\n",
    "            await self.publish_message(\n",
    "                message,\n",
    "                DefaultTopicId(type=self._group_manager_topic),\n",
    "            )\n",
    "        chat_history.append(UserMessage(content=last_msg.text, source=\"user\"))\n",
    "        while True:\n",
    "            completion = await self._model_client.create(\n",
    "                chat_history,\n",
    "                tools=self._tools,\n",
    "                cancellation_token=ctx.cancellation_token,\n",
    "            )\n",
    "            print(f\"### {self.type}: \\n{completion.content}\")\n",
    "            if not isinstance(completion.content, list):\n",
    "                message.chat_history.append(Message(text=completion.content, source=self.type))\n",
    "                await self.publish_message(\n",
    "                    message,\n",
    "                    DefaultTopicId(type=self._group_manager_topic),\n",
    "                )\n",
    "                \n",
    "                break\n",
    "            \n",
    "            # run tool call\n",
    "            for tool_call in completion.content:\n",
    "                arguments = tool_call.arguments\n",
    "                arguments = json.loads(tool_call.arguments)\n",
    "                if tool_call.name == self._get_date_tool.name:\n",
    "                    result = await self._get_date_tool.run_json(arguments, ctx.cancellation_token)\n",
    "                    reply = Message(text=self._get_date_tool.return_value_as_string(result))\n",
    "                    print(f\"### {self.type}: \\n{reply.text}\")\n",
    "                    await self.publish_message(\n",
    "                        reply,\n",
    "                        DefaultTopicId(type=self._group_manager_topic),\n",
    "                    )\n",
    "                    chat_history.append(AssistantMessage(content=[tool_call], source=\"assistant\"))\n",
    "                    chat_history.append(FunctionExecutionResultMessage(content=[FunctionExecutionResult(content=reply.text, call_id=tool_call.id)]))\n",
    "                elif tool_call.name == self._get_weather_tool.name:\n",
    "                    result = await self._get_weather_tool.run_json(arguments, ctx.cancellation_token)\n",
    "                    reply = Message(text=self._get_weather_tool.return_value_as_string(result))\n",
    "                    print(f\"### {self.type}: \\n{reply.text}\")\n",
    "                    await self.publish_message(\n",
    "                        reply,\n",
    "                        DefaultTopicId(type=self._group_manager_topic),\n",
    "                    )\n",
    "                    chat_history.append(AssistantMessage(content=[tool_call], source=\"assistant\"))\n",
    "                    chat_history.append(FunctionExecutionResultMessage(content=[FunctionExecutionResult(content=reply.text, call_id=tool_call.id)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant(RoutedAgent):\n",
    "    def __init__(self,\n",
    "                 model_client: ChatCompletionClient,\n",
    "                 system_message: str,\n",
    "                 group_manager_topic: str) -> None:\n",
    "        super().__init__(\"An assistant agent.\")\n",
    "        self._model_client = model_client\n",
    "        self._group_manager_topic = group_manager_topic\n",
    "        self._system_message = system_message\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        chat_history: List[LLMMessage] = [SystemMessage(content=self._system_message)]\n",
    "        for msg in message.chat_history:\n",
    "            if msg.source != self.type:\n",
    "                chat_history.append(UserMessage(content=msg.text, source=msg.source))\n",
    "            else:\n",
    "                chat_history.append(AssistantMessage(content=msg.text, source=\"assistant\"))\n",
    "\n",
    "        result = await self._model_client.create(chat_history)\n",
    "        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n",
    "        message.chat_history.append(Message(text=result.content, source=self.type))\n",
    "        await self.publish_message(message, DefaultTopicId(type=self._group_manager_topic))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupChatManager(RoutedAgent):\n",
    "    def __init__(self,\n",
    "                    model_client: ChatCompletionClient,\n",
    "                    weather_agent: str,\n",
    "                    weather_agent_description: str,\n",
    "                    image_agent: str,\n",
    "                    image_agent_description: str,\n",
    "                    user_agent: str,\n",
    "                    user_agent_description: str,\n",
    "                    assistant: str,\n",
    "                    assistant_description: str) -> None:\n",
    "        super().__init__(\"Group Chat Manager\")\n",
    "        self._model_client = model_client\n",
    "        self._weather_agent = weather_agent\n",
    "        self._weather_agent_description = weather_agent_description\n",
    "        self._image_agent = image_agent\n",
    "        self._image_agent_description = image_agent_description\n",
    "        self._user_agent = user_agent\n",
    "        self._user_agent_description = user_agent_description\n",
    "        self._assistant = assistant\n",
    "        self._assistant_description = assistant_description\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        # Format message history.\n",
    "        messages: List[str] = []\n",
    "        for msg in message.chat_history:\n",
    "            messages.append(f\"{msg.source}: {msg.text}\")\n",
    "        history = \"\\n\".join(messages)\n",
    "        # Format roles.\n",
    "        roles = \"\\n\".join(\n",
    "            [\n",
    "                f\"{topic_type}: {description}\".strip()\n",
    "                for topic_type, description in zip(\n",
    "                    [self._weather_agent, self._image_agent, self._user_agent, self._assistant],\n",
    "                    [\n",
    "                        self._weather_agent_description,\n",
    "                        self._image_agent_description,\n",
    "                        self._user_agent_description,\n",
    "                        self._assistant_description,\n",
    "                    ],\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        selector_prompt = \"\"\"You are in a role play game. The following roles are available:\n",
    "{roles}.\n",
    "Read the following conversation. Then select the next role from {participants} to play. Only return the role.\n",
    "\n",
    "{history}\n",
    "\n",
    "Read the above conversation. Then select the next role from {participants} to play. Only return the role.\n",
    "\"\"\"\n",
    "        available_roles = [\n",
    "            self._weather_agent,\n",
    "            self._image_agent,\n",
    "            self._user_agent,\n",
    "            self._assistant,\n",
    "        ]\n",
    "        system_message = SystemMessage(\n",
    "            selector_prompt.format(\n",
    "                roles=roles,\n",
    "                history=history,\n",
    "                participants=str(\n",
    "                    [\n",
    "                        topic_type\n",
    "                        for topic_type in available_roles\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        completion = await self._model_client.create([system_message])\n",
    "        assert isinstance(completion.content, str)\n",
    "        for topic_type in available_roles:\n",
    "            if topic_type.lower() in completion.content.lower():\n",
    "                print(f\"### {self.type}: \\nSelected role: {topic_type}\")\n",
    "                await self.publish_message(message, DefaultTopicId(type=topic_type))\n",
    "                return\n",
    "        raise ValueError(f\"Invalid role selected: {completion.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: \n",
      "What's the weather in seattle\n",
      "### admin: \n",
      "Selected role: weather\n",
      "### weather: \n",
      "[FunctionCall(id='call_1xZpc5c0atpKLjwuZsE6aR4f', arguments='{\"city\":\"Seattle\",\"state\":\"WA\",\"date\":\"2023-10-01\"}', name='get_weather')]\n",
      "Getting the weather for Seattle, WA on 2023-10-01\n",
      "### weather: \n",
      "The weather in Seattle, WA on 2023-10-01 will be sunny.\n",
      "### weather: \n",
      "The weather in Seattle, WA on October 1, 2023, is expected to be sunny.\n",
      "### admin: \n",
      "Selected role: user\n",
      "### User: \n",
      "What's the weather in seattle today\n",
      "### admin: \n",
      "Selected role: weather\n",
      "### weather: \n",
      "[FunctionCall(id='call_AZ3ondsMBPeCgjxwG7W6WGNx', arguments='{}', name='get_date')]\n",
      "### weather: \n",
      "today is 2024-10-25\n",
      "### weather: \n",
      "[FunctionCall(id='call_l0rQlat6E8ytlTu6ngLivEbD', arguments='{\"city\":\"Seattle\",\"state\":\"WA\",\"date\":\"2024-10-25\"}', name='get_weather')]\n",
      "Getting the weather for Seattle, WA on 2024-10-25\n",
      "### weather: \n",
      "The weather in Seattle, WA on 2024-10-25 will be sunny.\n",
      "### weather: \n",
      "The weather in Seattle, WA today (October 25, 2024) is sunny.\n",
      "### admin: \n",
      "Selected role: assistant\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "I'm sorry, but I can't provide live weather updates. You can check a reliable weather website or app for the most current weather conditions in Seattle today.\n",
      "### admin: \n",
      "Selected role: user\n",
      "### User: \n",
      "Tell a joke\n",
      "### admin: \n",
      "Selected role: assistant\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "Sure! Here’s one for you:\n",
      "\n",
      "Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field!\n",
      "### admin: \n",
      "Selected role: user\n",
      "### User: \n",
      "Summarize the conversation\n",
      "### admin: \n",
      "Selected role: assistant\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "In this conversation, the user first inquired about the weather in Seattle. I provided a response about the weather for October 1, 2023, and later mentioned October 25, 2024, but clarified that I can't provide live updates. The user then asked for a joke, and I shared a light-hearted joke about a scarecrow.\n",
      "### admin: \n",
      "Selected role: user\n",
      "### User: \n",
      "What's in this picture: C:\\Users\\xiaoyuz\\source\\repos\\Develop_Agent_With_AutoGen\\images\\cat under banana.jpg\n",
      "### admin: \n",
      "Selected role: image\n",
      "### image: \n",
      "The image features a cat with a banana placed on its head. The cat appears to have gray fur with a white patch on its chest and is resting against a wooden surface. The background shows a hint of a wall, possibly with a light-colored wallpaper.\n",
      "### admin: \n",
      "Selected role: user\n",
      "### User: \n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "gpt_4o_mini = OpenAIChatCompletionClient(\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            model=\"gpt-4o-mini\",\n",
    "        )\n",
    "gpt_4o = OpenAIChatCompletionClient(\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            model=\"gpt-4o\",\n",
    "        )\n",
    "user_agent_description = \"A user agent that generates messages for the assistant agent.\"\n",
    "user_agent = await UserAgent.register(\n",
    "    runtime,\n",
    "    type=\"user\",\n",
    "    factory=lambda: UserAgent(\n",
    "        description=user_agent_description,\n",
    "        group_manager_topic=\"admin\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "image_agent_description = \"An agent that processes images.\"\n",
    "image_agent = await ImageAssistant.register(\n",
    "    runtime,\n",
    "    type=\"image\",\n",
    "    factory=lambda: ImageAssistant(\n",
    "        model_client=gpt_4o_mini,\n",
    "        system_message=\"You are an AI assistant that can process images.\",\n",
    "        group_manager_topic=\"admin\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "weather_agent_description = \"An agent that provides weather information.\"\n",
    "weather_agent = await WeatherAssistant.register(\n",
    "    runtime,\n",
    "    type=\"weather\",\n",
    "    factory=lambda: WeatherAssistant(\n",
    "        model_client=gpt_4o_mini,\n",
    "        system_message=\"You are a helpful AI assistant that can provide weather information.\",\n",
    "        group_manager_topic=\"admin\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "assistant_description = \"An assistant agent that can help with various tasks.\"\n",
    "assistant = await Assistant.register(\n",
    "    runtime,\n",
    "    type=\"assistant\",\n",
    "    factory=lambda: Assistant(model_client=gpt_4o_mini, system_message=\"You are a helpful AI assistant\", group_manager_topic=\"admin\"),\n",
    ")\n",
    "\n",
    "group_manager_description = \"A group chat manager that routes messages to the appropriate agent.\"\n",
    "group_manager = await GroupChatManager.register(\n",
    "    runtime,\n",
    "    type=\"admin\",\n",
    "    factory=lambda: GroupChatManager(\n",
    "        model_client=gpt_4o,\n",
    "        weather_agent=weather_agent.type,\n",
    "        weather_agent_description=weather_agent_description,\n",
    "        image_agent=image_agent.type,\n",
    "        image_agent_description=image_agent_description,\n",
    "        user_agent=user_agent.type,\n",
    "        user_agent_description=user_agent_description,\n",
    "        assistant=assistant.type,\n",
    "        assistant_description=assistant_description,\n",
    "    ),\n",
    ")\n",
    "\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"user\", user_agent.type))\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"assistant\", assistant.type))\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"image\", image_agent.type))\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"weather\", weather_agent.type))\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"admin\", group_manager.type))\n",
    "\n",
    "runtime.start()\n",
    "session_id = str(uuid.uuid4())\n",
    "msg = Conversation(chat_history=[])\n",
    "await runtime.publish_message(\n",
    "    msg,\n",
    "    TopicId(type=\"user\", source=session_id),\n",
    ")\n",
    "\n",
    "await runtime.stop_when_idle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
