{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Agent GroupChat\n",
    "In the previous example, we show how to introduce human-in-the-loop to a two-agent chat conversation. In this example, we extend the previous example to a multi-agent chat conversation.\n",
    "\n",
    "### Motivation\n",
    "Similar to the group chat in our daily conversation, we can also introduce multiple agents into the same group where each agent can have its own personality and knowledge. This can be useful in many applications, such as customer service, where multiple agents can work together to provide better service to the customers.\n",
    "\n",
    "### Scenario\n",
    "In this notebook, we will show how to use the following agents to create a group chat conversation that hosts all the agents we created in the previous examples:\n",
    "- User: ask questions\n",
    "- WeatherAssistant: provides the weather information using tool call.\n",
    "- ImageAssistant: provides the information of the image using multi-modal model.\n",
    "- Assistant: Answer generic questions.\n",
    "- Manager: orchestrates the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from autogen_core.base import MessageContext, AgentId, AgentInstantiationContext, TopicId\n",
    "from autogen_core.components import DefaultTopicId, RoutedAgent, default_subscription, message_handler, TypeSubscription\n",
    "from autogen_core.components.code_executor import CodeExecutor, extract_markdown_code_blocks\n",
    "from autogen_core.components.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "import tempfile\n",
    "from autogen_core.components.tool_agent import ToolAgent, tool_agent_caller_loop\n",
    "from autogen_core.application import SingleThreadedAgentRuntime\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient\n",
    "import random\n",
    "import json\n",
    "from autogen_core.base import CancellationToken\n",
    "from autogen_core.components.tools import FunctionTool, ToolSchema\n",
    "from autogen_core.components._image import Image\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import uuid;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    text: str\n",
    "    source: Optional[str] = None\n",
    "    image_url: Optional[str] = None # url or base64 encoded image\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    chat_history: List[Message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserAgent(RoutedAgent):\n",
    "    def __init__(self, description: str, group_manager_topic: str) -> None:\n",
    "        super().__init__(description=description)\n",
    "        self._group_manager_topic = group_manager_topic\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_request_to_speak(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        user_input = input(\"Enter your message, type 'TERMINATE' to terminate the task: \")\n",
    "        print(f\"### User: \\n{user_input}\")\n",
    "        if user_input == \"TERMINATE\": # end the conversation\n",
    "            return\n",
    "        \n",
    "        message.chat_history.append(Message(text=user_input, source=self.type))\n",
    "        await self.publish_message(\n",
    "            message,\n",
    "            DefaultTopicId(type=self._group_manager_topic),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAssistant(RoutedAgent):\n",
    "    def __init__(self,\n",
    "                 model_client: ChatCompletionClient,\n",
    "                 system_message: str,\n",
    "                 group_manager_topic: str) -> None:\n",
    "        super().__init__(description=system_message)\n",
    "        self._system_message = system_message\n",
    "        self._group_manager_topic = group_manager_topic\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_request_to_speak(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        chat_history: List[LLMMessage] = [SystemMessage(content=self._system_message)]\n",
    "        last_msg = message.chat_history[-1]\n",
    "        if last_msg.image_url is None:\n",
    "            reply = Message(text=\"No image in the last message\", source=self.type)\n",
    "            message.chat_history.append(reply)\n",
    "            await self.publish_message(\n",
    "                message,\n",
    "                DefaultTopicId(type=self._group_manager_topic),\n",
    "            )\n",
    "        \n",
    "        userMessage = UserMessage([last_msg.text, Image.from_base64(last_msg.image_url)])\n",
    "        chat_history.append(userMessage)\n",
    "        completion = await self._model_client.complete_chat(chat_history)\n",
    "        response = completion.messages[-1]\n",
    "        reply = Message(text=response.text, source=self.type)\n",
    "        message.chat_history.append(reply)\n",
    "        await self.publish_message(\n",
    "            message,\n",
    "            DefaultTopicId(type=self._group_manager_topic),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherAssistant(RoutedAgent):\n",
    "    def __init__(self,\n",
    "                 model_client: ChatCompletionClient,\n",
    "                 system_message: str,\n",
    "                 group_manager_topic: str) -> None:\n",
    "        super().__init__(description=system_message)\n",
    "        self._system_message = system_message\n",
    "        self._group_manager_topic = group_manager_topic\n",
    "        self._model_client = model_client\n",
    "        self._get_weather_tool = FunctionTool(self.get_weather, description=\"get weather from a city and state\")\n",
    "        self._tools = [self._get_weather_tool]\n",
    "\n",
    "    # get weather tool\n",
    "    async def get_weather(self, city: str, state: str) -> str: # is the return type matter here?\n",
    "    # get the weather for a city and state\n",
    "        print(f\"Getting the weather for {city}, {state}\")\n",
    "        return f\"The weather in {city}, {state} is sunny.\"\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_request_to_speak(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        chat_history: List[LLMMessage] = [SystemMessage(content=self._system_message)]\n",
    "        last_msg = message.chat_history[-1]\n",
    "        if last_msg.image_url is not None:\n",
    "            reply = Message(text=\"can't recognize image in the last message\", source=self.type)\n",
    "            message.chat_history.append(reply)\n",
    "            await self.publish_message(\n",
    "                message,\n",
    "                DefaultTopicId(type=self._group_manager_topic),\n",
    "            )\n",
    "        chat_history.append(UserMessage(content=last_msg.text, source=\"user\"))\n",
    "        completion = await self._model_client.create(\n",
    "            chat_history,\n",
    "            tools=self._tools,\n",
    "            extra_create_args={\"tool_choice\": \"required\"},\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        print(f\"### {self.type}: \\n{completion.content}\")\n",
    "        if not isinstance(completion.content, list):\n",
    "            reply = Message(text=\"Error in tool call\", source=self.type)\n",
    "            print(f\"### {self.type}: \\n{reply.text}\")\n",
    "            message.chat_history.append(reply)\n",
    "            await self.publish_message(\n",
    "                message,\n",
    "                DefaultTopicId(type=self._group_manager_topic),\n",
    "            )\n",
    "\n",
    "            return\n",
    "        # run tool call\n",
    "        for tool_call in completion.content:\n",
    "            arguments = tool_call.arguments\n",
    "            arguments = json.loads(tool_call.arguments)\n",
    "            result = await self._get_weather_tool.run_json(arguments, ctx.cancellation_token)\n",
    "            reply = Message(text=self._get_weather_tool.return_value_as_string(result), source=self.type)\n",
    "            print(f\"### {self.type}: \\n{reply.text}\")\n",
    "            message.chat_history.append(reply)\n",
    "            await self.publish_message(\n",
    "                message,\n",
    "                DefaultTopicId(type=self._group_manager_topic),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant(RoutedAgent):\n",
    "    def __init__(self,\n",
    "                 model_client: ChatCompletionClient,\n",
    "                 system_message: str,\n",
    "                 group_manager_topic: str) -> None:\n",
    "        super().__init__(\"An assistant agent.\")\n",
    "        self._model_client = model_client\n",
    "        self._group_manager_topic = group_manager_topic\n",
    "        self._system_message = system_message\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        chat_history: List[LLMMessage] = [SystemMessage(content=self._system_message)]\n",
    "        for msg in message.chat_history:\n",
    "            if msg.source != self.type:\n",
    "                chat_history.append(UserMessage(content=msg.text, source=msg.source))\n",
    "            else:\n",
    "                chat_history.append(AssistantMessage(content=msg.text, source=\"assistant\"))\n",
    "\n",
    "        result = await self._model_client.create(chat_history)\n",
    "        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n",
    "        message.chat_history.append(Message(text=result.content, source=self.type))\n",
    "        await self.publish_message(message, DefaultTopicId(type=self._group_manager_topic))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupChatManager(RoutedAgent):\n",
    "    def __init__(self,\n",
    "                    model_client: ChatCompletionClient,\n",
    "                    weather_agent: str,\n",
    "                    weather_agent_description: str,\n",
    "                    image_agent: str,\n",
    "                    image_agent_description: str,\n",
    "                    user_agent: str,\n",
    "                    user_agent_description: str,\n",
    "                    assistant: str,\n",
    "                    assistant_description: str) -> None:\n",
    "        super().__init__(\"Group Chat Manager\")\n",
    "        self._model_client = model_client\n",
    "        self._weather_agent = weather_agent\n",
    "        self._weather_agent_description = weather_agent_description\n",
    "        self._image_agent = image_agent\n",
    "        self._image_agent_description = image_agent_description\n",
    "        self._user_agent = user_agent\n",
    "        self._user_agent_description = user_agent_description\n",
    "        self._assistant = assistant\n",
    "        self._assistant_description = assistant_description\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Conversation, ctx: MessageContext) -> None:\n",
    "        # Format message history.\n",
    "        messages: List[str] = []\n",
    "        for msg in message.chat_history:\n",
    "            messages.append(f\"{msg.source}: {msg.text}\")\n",
    "        history = \"\\n\".join(messages)\n",
    "        # Format roles.\n",
    "        roles = \"\\n\".join(\n",
    "            [\n",
    "                f\"{topic_type}: {description}\".strip()\n",
    "                for topic_type, description in zip(\n",
    "                    [self._weather_agent, self._image_agent, self._user_agent, self._assistant],\n",
    "                    [\n",
    "                        self._weather_agent_description,\n",
    "                        self._image_agent_description,\n",
    "                        self._user_agent_description,\n",
    "                        self._assistant_description,\n",
    "                    ],\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        selector_prompt = \"\"\"You are in a role play game. The following roles are available:\n",
    "{roles}.\n",
    "Read the following conversation. Then select the next role from {participants} to play. Only return the role.\n",
    "\n",
    "{history}\n",
    "\n",
    "Read the above conversation. Then select the next role from {participants} to play. Only return the role.\n",
    "\"\"\"\n",
    "        available_roles = [\n",
    "            self._weather_agent,\n",
    "            self._image_agent,\n",
    "            self._user_agent,\n",
    "            self._assistant,\n",
    "        ]\n",
    "        system_message = SystemMessage(\n",
    "            selector_prompt.format(\n",
    "                roles=roles,\n",
    "                history=history,\n",
    "                participants=str(\n",
    "                    [\n",
    "                        topic_type\n",
    "                        for topic_type in available_roles\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        completion = await self._model_client.create([system_message])\n",
    "        assert isinstance(completion.content, str)\n",
    "        for topic_type in available_roles:\n",
    "            if topic_type.lower() in completion.content.lower():\n",
    "                print(f\"### {self.type}: \\nSelected role: {topic_type}\")\n",
    "                await self.publish_message(message, DefaultTopicId(type=topic_type))\n",
    "                return\n",
    "        raise ValueError(f\"Invalid role selected: {completion.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: \n",
      "Make a joke about newyork current weather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyuz\\AppData\\Local\\Temp\\ipykernel_33692\\2242232903.py:72: UserWarning: Resolved model mismatch: gpt-4o-2024-05-13 != gpt-4o-2024-08-06. Model mapping may be incorrect.\n",
      "  completion = await self._model_client.create([system_message])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### admin: \n",
      "Selected role: weather\n",
      "### weather: \n",
      "[FunctionCall(id='call_Z8cke9Mcag1SFGHTyAW0BCOR', arguments='{\"city\":\"New York\",\"state\":\"NY\"}', name='get_weather')]\n",
      "Getting the weather for New York, NY\n",
      "### weather: \n",
      "The weather in New York, NY is sunny.\n",
      "### admin: \n",
      "Selected role: assistant\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "Why did the sun go to school in New York?\n",
      "\n",
      "Because it wanted to get a little \"brighter\" with all that sunny weather! ☀️\n",
      "### admin: \n",
      "Selected role: user\n",
      "### User: \n",
      "Make another one about seattle current weather\n",
      "### admin: \n",
      "Selected role: weather\n",
      "### weather: \n",
      "[FunctionCall(id='call_yYJuVrWjAB617SUiMNnqHPvW', arguments='{\"city\":\"Seattle\",\"state\":\"WA\"}', name='get_weather')]\n",
      "Getting the weather for Seattle, WA\n",
      "### weather: \n",
      "The weather in Seattle, WA is sunny.\n",
      "### admin: \n",
      "Selected role: assistant\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "Why did the coffee file a police report in Seattle?\n",
      "\n",
      "Because it got mugged... but luckily, it's a sunny day, so it perked right back up! ☕☀️\n",
      "### admin: \n",
      "Selected role: user\n",
      "### User: \n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "gpt_4o_mini = OpenAIChatCompletionClient(\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            model=\"gpt-4o-mini\",\n",
    "        )\n",
    "gpt_4o = OpenAIChatCompletionClient(\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            model=\"gpt-4o\",\n",
    "        )\n",
    "user_agent_description = \"A user agent that generates messages for the assistant agent.\"\n",
    "user_agent = await UserAgent.register(\n",
    "    runtime,\n",
    "    type=\"user\",\n",
    "    factory=lambda: UserAgent(\n",
    "        description=user_agent_description,\n",
    "        group_manager_topic=\"admin\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "image_agent_description = \"An agent that processes images.\"\n",
    "image_agent = await ImageAssistant.register(\n",
    "    runtime,\n",
    "    type=\"image\",\n",
    "    factory=lambda: ImageAssistant(\n",
    "        model_client=gpt_4o_mini,\n",
    "        system_message=\"You are an AI assistant that can process images.\",\n",
    "        group_manager_topic=\"admin\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "weather_agent_description = \"An agent that provides weather information.\"\n",
    "weather_agent = await WeatherAssistant.register(\n",
    "    runtime,\n",
    "    type=\"weather\",\n",
    "    factory=lambda: WeatherAssistant(\n",
    "        model_client=gpt_4o_mini,\n",
    "        system_message=\"You are a helpful AI assistant that can provide weather information.\",\n",
    "        group_manager_topic=\"admin\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "assistant_description = \"An assistant agent that can help with various tasks.\"\n",
    "assistant = await Assistant.register(\n",
    "    runtime,\n",
    "    type=\"assistant\",\n",
    "    factory=lambda: Assistant(model_client=gpt_4o_mini, system_message=\"You are a helpful AI assistant\", group_manager_topic=\"admin\"),\n",
    ")\n",
    "\n",
    "group_manager_description = \"A group chat manager that routes messages to the appropriate agent.\"\n",
    "group_manager = await GroupChatManager.register(\n",
    "    runtime,\n",
    "    type=\"admin\",\n",
    "    factory=lambda: GroupChatManager(\n",
    "        model_client=gpt_4o,\n",
    "        weather_agent=weather_agent.type,\n",
    "        weather_agent_description=weather_agent_description,\n",
    "        image_agent=image_agent.type,\n",
    "        image_agent_description=image_agent_description,\n",
    "        user_agent=user_agent.type,\n",
    "        user_agent_description=user_agent_description,\n",
    "        assistant=assistant.type,\n",
    "        assistant_description=assistant_description,\n",
    "    ),\n",
    ")\n",
    "\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"user\", user_agent.type))\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"assistant\", assistant.type))\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"image\", image_agent.type))\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"weather\", weather_agent.type))\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(\"admin\", group_manager.type))\n",
    "\n",
    "runtime.start()\n",
    "session_id = str(uuid.uuid4())\n",
    "msg = Conversation(chat_history=[])\n",
    "await runtime.publish_message(\n",
    "    msg,\n",
    "    TopicId(type=\"user\", source=session_id),\n",
    ")\n",
    "\n",
    "await runtime.stop_when_idle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
