{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool calling and Multi-Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from autogen_core.base import MessageContext, AgentId, AgentInstantiationContext\n",
    "from autogen_core.components import DefaultTopicId, RoutedAgent, default_subscription, message_handler\n",
    "from autogen_core.components.code_executor import CodeExecutor, extract_markdown_code_blocks\n",
    "from autogen_core.components.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "import tempfile\n",
    "from autogen_core.components.tool_agent import ToolAgent, tool_agent_caller_loop\n",
    "from autogen_core.application import SingleThreadedAgentRuntime\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient\n",
    "import random\n",
    "\n",
    "from autogen_core.base import CancellationToken\n",
    "from autogen_core.components.tools import FunctionTool, ToolSchema\n",
    "from autogen_core.components._image import Image\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is tool calling?\n",
    "\n",
    "Tool call is essentially a function that can be executed by LLM or agent. A tool is consisted by two parts\n",
    "- schema: the function signature and the description of the function\n",
    "- function: the actual implementation of the function\n",
    "\n",
    "Where the schema is used by LLM to generate the function arguments. When the function arguments are received, the corresponding function will be invoked with the given arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a tool\n",
    "\n",
    "In AutoGen, to define a tool, simply create a python function and use `FunctionTool` class to wrap it. The `FunctionTool` class will automatically generate the schema for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_weather(city: str, state: str) -> str: # is the return type matter here?\n",
    "# get the weather for a city and state\n",
    "    print(f\"Getting the weather for {city}, {state}\")\n",
    "    return f\"The weather in {city}, {state} is sunny.\"\n",
    "\n",
    "# Create a get_weather tool\n",
    "get_weather_tool = FunctionTool(get_weather, description=\"Get the weather for a city and state.\")\n",
    "get_weather_tool.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AutoGen Assistant Agent\n",
    "\n",
    "The assistant will be invoked when it receives a `Message` from agent runtime. Then it will use LLM to generate a response message and publish it back to the agent runtime.\n",
    "\n",
    "The assistant has `default_subscription`, which means it subscribles to messages with all topics from the agent runtime.\n",
    "\n",
    "The assistant agent uses `tool_agent_caller_loop` utility function to send a message to the tool agent and get the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    text: str\n",
    "    source: Optional[str] = None\n",
    "\n",
    "@default_subscription\n",
    "class WeatherAssistant(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient, get_weather_tool: FunctionTool) -> None:\n",
    "        super().__init__(\"An agent with tools\")\n",
    "        self._system_messages: List[LLMMessage] = [SystemMessage(\"You are a helpful AI assistant.\")]\n",
    "        self._model_client = model_client\n",
    "        self._get_weather_tool = get_weather_tool\n",
    "        self._tools = [get_weather_tool]\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_text_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        # Create a session of messages.\n",
    "        session: List[LLMMessage] = [UserMessage(content=message.text, source=\"user\")]\n",
    "        # Run the caller loop to handle tool calls.\n",
    "        # the tool_agent_caller_loop function will call the tool agent to handle the tool calls if exists.\n",
    "        completion = await self._model_client.create(\n",
    "            session,\n",
    "            tools=self._tools,\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        print(f\"### {self.type}: \\n{completion.content}\")\n",
    "        if not isinstance(completion.content, list):\n",
    "            await self.publish_message(\n",
    "                Message(text=completion.content),\n",
    "                DefaultTopicId(),\n",
    "            )\n",
    "        # run tool call\n",
    "        for tool_call in completion.content:\n",
    "            arguments = tool_call.arguments\n",
    "            arguments = json.loads(tool_call.arguments)\n",
    "            result = await self._get_weather_tool.run_json(arguments, ctx.cancellation_token)\n",
    "            reply = Message(text=self._get_weather_tool.return_value_as_string(result))\n",
    "            print(f\"### {self.type}: \\n{reply.text}\")\n",
    "            await self.publish_message(\n",
    "                reply,\n",
    "                DefaultTopicId(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add assistant agent to the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an local embedded runtime.\n",
    "import os;\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await WeatherAssistant.register(\n",
    "        runtime,\n",
    "        \"assistant\",\n",
    "        lambda: WeatherAssistant(\n",
    "            OpenAIChatCompletionClient(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                # get api key from env:OPENAI_API_KEY\n",
    "                api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            ),\n",
    "            get_weather_tool,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a message to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the runtime and publish a message to the assistant.\n",
    "runtime.start()\n",
    "await runtime.publish_message(\n",
    "    Message(text = \"Hello, I am Geeno, what's the weather in New York\"), DefaultTopicId()\n",
    ")\n",
    "\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have successfully created a simple tool agent and an assistant agent. And how to enable multi-modal chat in AutoGen.\n",
    "\n",
    "## What we have learned\n",
    "- How to create a tool agent\n",
    "- How to equip the agent with an assistant\n",
    "- How to enable multi-modal chat in assistant agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
