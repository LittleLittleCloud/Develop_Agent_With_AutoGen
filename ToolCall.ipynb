{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool call\n",
    "\n",
    "### What is Tool Call?\n",
    "\n",
    "Tool call is one of the most useful, the most fundamental and the most important LLM ability in agent development. In tool calling, LLM generates a specific format output to invoke function from user's code. The function execution result can then be sent back to LLM for further processing. Tool call greatly extends the capability of LLM from text in, text out to text in, action out.\n",
    "\n",
    "In this notebook, we will show you how to add tool call ability to your agent. We will create a weather agent which can provides dummy weather information. The agent will have a `get_weather` tool to retrieve weather information from a given city and given date. And also a `get_current_date` tool to get the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyuz\\AppData\\Local\\Temp\\ipykernel_100116\\147059402.py:19: FutureWarning: OpenAIChatCompletionClient moved to autogen_ext. Please import it from autogen_ext.modelsChatCompletionClient.\n",
      "  from autogen_core.components.models import OpenAIChatCompletionClient, FunctionExecutionResultMessage, FunctionExecutionResult\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import datetime\n",
    "from typing import List, Optional\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from autogen_core.base import MessageContext, AgentId, AgentInstantiationContext\n",
    "from autogen_core.components import DefaultTopicId, RoutedAgent, default_subscription, message_handler\n",
    "from autogen_core.components.code_executor import CodeExecutor, extract_markdown_code_blocks\n",
    "from autogen_core.components.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "import tempfile\n",
    "from autogen_core.components.tool_agent import ToolAgent, tool_agent_caller_loop\n",
    "from autogen_core.application import SingleThreadedAgentRuntime\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient, FunctionExecutionResultMessage, FunctionExecutionResult\n",
    "import random\n",
    "\n",
    "from autogen_core.base import CancellationToken\n",
    "from autogen_core.components.tools import FunctionTool, ToolSchema\n",
    "from autogen_core.components._image import Image\n",
    "from autogen_core.components._types import FunctionCall\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Message data class\n",
    "The `Message` class is a data contract class that holds a text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    text: str\n",
    "    source: Optional[str] = None # indicate which agent the message is from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a tool\n",
    "\n",
    "In AutoGen, to define a tool, simply create a python function and use `FunctionTool` class to wrap it. The `FunctionTool` class will automatically generate the schema for the function. The schema contains the description of the function, the input parameters and the output parameters, and is sent to LLM to help LLM understand the tool and how to call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_weather',\n",
       " 'description': 'Get the weather for a city and state on a given date.',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'city': {'description': 'city',\n",
       "    'title': 'City',\n",
       "    'type': 'string'},\n",
       "   'state': {'description': 'state', 'title': 'State', 'type': 'string'},\n",
       "   'date': {'description': 'date', 'title': 'Date', 'type': 'string'}},\n",
       "  'required': ['city', 'state', 'date']}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def get_weather(city: str, state: str, date: str) -> str: # is the return type matter here?\n",
    "    print(f\"Getting the weather for {city}, {state}\")\n",
    "    return f\"The weather in {city}, {state} on {date} will be sunny.\"\n",
    "\n",
    "# Create a get_weather tool\n",
    "get_weather_tool = FunctionTool(get_weather, description=\"Get the weather for a city and state on a given date.\")\n",
    "get_weather_tool.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create WeatherAssistant Agent\n",
    "\n",
    "The `WeatherAssistant` has two tools:\n",
    "- `get_weather`: Get weather information from a given city and a given date.\n",
    "- `get_current_date`: Get the current date.\n",
    "\n",
    "It has one message handler registered. The message handler will be invoked when it receives a `Message` from agent runtime. And it will invoke LLM to generate a response.\n",
    "\n",
    "When making request to LLM, the schemas of both tools are also sent to LLM. LLM will determine which tool to call based on the input message. If a `tool_call` response is received, the message handler will invoke the corresponding tool and send the result back to LLM for further processing. If a normal response is received, the message handler will publish the response to the agent runtime without further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@default_subscription\n",
    "class WeatherAssistant(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"An agent with tools\")\n",
    "        self._system_messages: List[LLMMessage] = [SystemMessage(\"You are a helpful AI assistant.\")]\n",
    "        self._model_client = model_client\n",
    "        self._get_weather_tool = FunctionTool(self.get_weather, description=\"Get the weather for a city and state on a given date.\")\n",
    "        self._get_date_tool = FunctionTool(self.get_date, description=\"Get the current date.\")\n",
    "        self._tools = [self._get_date_tool, self._get_weather_tool]\n",
    "\n",
    "    async def get_weather(self, city: str, state: str, date: str) -> str: # is the return type matter here?\n",
    "    # get the weather for a city and state\n",
    "        print(f\"Getting the weather for {city}, {state} on {date}\")\n",
    "        return f\"The weather in {city}, {state} on {date} will be sunny.\"\n",
    "    \n",
    "    async def get_date(self) -> str:\n",
    "        today = datetime.datetime.today()\n",
    "        return f\"today is {today.strftime('%Y-%m-%d')}\"\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_text_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        # Create a session of messages.\n",
    "        session: List[LLMMessage] = [UserMessage(content=message.text, source=\"user\")]\n",
    "\n",
    "        while True:\n",
    "            completion = await self._model_client.create(\n",
    "                session,\n",
    "                tools=self._tools,\n",
    "                cancellation_token=ctx.cancellation_token,\n",
    "            )\n",
    "            print(f\"### {self.type}: \\n{completion.content}\")\n",
    "            if not isinstance(completion.content, list):\n",
    "                await self.publish_message(\n",
    "                    Message(text=completion.content),\n",
    "                    DefaultTopicId(),\n",
    "                )\n",
    "                \n",
    "                break\n",
    "            \n",
    "            # run tool call\n",
    "            for tool_call in completion.content:\n",
    "                arguments = tool_call.arguments\n",
    "                arguments = json.loads(tool_call.arguments)\n",
    "                if tool_call.name == self._get_date_tool.name:\n",
    "                    result = await self._get_date_tool.run_json(arguments, ctx.cancellation_token)\n",
    "                    reply = Message(text=self._get_date_tool.return_value_as_string(result))\n",
    "                    print(f\"### {self.type}: \\n{reply.text}\")\n",
    "                    await self.publish_message(\n",
    "                        reply,\n",
    "                        DefaultTopicId(),\n",
    "                    )\n",
    "                    session.append(AssistantMessage(content=[tool_call], source=\"assistant\"))\n",
    "                    session.append(FunctionExecutionResultMessage(content=[FunctionExecutionResult(content=reply.text, call_id=tool_call.id)]))\n",
    "                elif tool_call.name == self._get_weather_tool.name:\n",
    "                    result = await self._get_weather_tool.run_json(arguments, ctx.cancellation_token)\n",
    "                    reply = Message(text=self._get_weather_tool.return_value_as_string(result))\n",
    "                    print(f\"### {self.type}: \\n{reply.text}\")\n",
    "                    await self.publish_message(\n",
    "                        reply,\n",
    "                        DefaultTopicId(),\n",
    "                    )\n",
    "                    session.append(AssistantMessage(content=[tool_call], source=\"assistant\"))\n",
    "                    session.append(FunctionExecutionResultMessage(content=[FunctionExecutionResult(content=reply.text, call_id=tool_call.id)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add assistant agent to the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='assistant')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an local embedded runtime.\n",
    "import os;\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await WeatherAssistant.register(\n",
    "        runtime,\n",
    "        \"assistant\",\n",
    "        lambda: WeatherAssistant(\n",
    "            OpenAIChatCompletionClient(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                # get api key from env:OPENAI_API_KEY\n",
    "                api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a message to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### assistant: \n",
      "[FunctionCall(id='call_7UclTIJNK840BJdUp1rIGk9d', arguments='{}', name='get_date')]\n",
      "### assistant: \n",
      "today is 2024-10-25\n",
      "### assistant: \n",
      "[FunctionCall(id='call_ON1vC83ybFG0LHVu1mTFt8CP', arguments='{\"city\":\"New York\",\"state\":\"NY\",\"date\":\"2024-10-25\"}', name='get_weather')]\n",
      "Getting the weather for New York, NY on 2024-10-25\n",
      "### assistant: \n",
      "The weather in New York, NY on 2024-10-25 will be sunny.\n",
      "### assistant: \n",
      "Hello Geeno! The weather in New York today (October 25, 2024) is sunny.\n"
     ]
    }
   ],
   "source": [
    "# Start the runtime and publish a message to the assistant.\n",
    "runtime.start()\n",
    "await runtime.publish_message(\n",
    "    Message(text = \"Hello, I am Geeno, what's the weather in New York today\"), DefaultTopicId()\n",
    ")\n",
    "\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have successfully created a weather assistant agent which can query weather information for a given city and date.\n",
    "\n",
    "## What we have learned\n",
    "- How to create a tool.\n",
    "- How to equip the agent with a tool.\n",
    "- How to process tool call in the message handler."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
