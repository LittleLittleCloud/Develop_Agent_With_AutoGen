{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World, AutoGen\n",
    "\n",
    "In this notebook, we will implement a simple `Assistant` Agent which generates hello-world message to user using `gpt-4o-mini` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyuz\\AppData\\Local\\Temp\\ipykernel_91220\\2560692345.py:14: FutureWarning: OpenAIChatCompletionClient moved to autogen_ext. Please import it from autogen_ext.modelsChatCompletionClient.\n",
      "  from autogen_core.components.models import OpenAIChatCompletionClient\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from typing import List, Optional\n",
    "from autogen_core.base import MessageContext\n",
    "from autogen_core.components import DefaultTopicId, RoutedAgent, default_subscription, message_handler\n",
    "from autogen_core.components.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "from pydantic import BaseModel\n",
    "from autogen_core.application import SingleThreadedAgentRuntime\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Message data class\n",
    "The `Message` class is a data contract class that holds a text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    text: str\n",
    "    source: Optional[str] = None # indicate which agent the message is from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AutoGen Assistant Agent\n",
    "\n",
    "The assistant will be invoked when it receives a `Message` from agent runtime. Then it will use LLM to generate a response message and publish it back to the agent runtime. This is implemented in `handle_message` message handler.\n",
    "\n",
    "### What is agent runtime?\n",
    "Agent runtime is a fundation layer provided by AutoGen 0.4x framework that facilitates the communication between agents. Agent can publish messages to agent runtime, and subscribe to messages from agent runtime.\n",
    "\n",
    "### How to create a message handler to process message from agent runtime?\n",
    "In AutoGen, you create a message handler for an agent by decorating a method with `@message_handler` decorator. The method needs to have a `message` parameter with the type of the message that this handler wants to handle.\n",
    "\n",
    "### How is a message handler invoked?\n",
    "When an agent receives a message from agent runtime, the agent runtime will look for a message handler that can handle the message based on the message type. If a message handler is found, it will be invoked with the message as the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@default_subscription\n",
    "class Assistant(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"An assistant agent.\")\n",
    "        self._model_client = model_client\n",
    "        self._chat_history: List[LLMMessage] = [\n",
    "            SystemMessage(\n",
    "                content=\"\"\"\n",
    "            You are a helpful AI assistant. You greet the user by saying 'Hello World <name>! How can I help you today?'.\n",
    "            \"\"\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        self._chat_history.append(UserMessage(content=message.text, source=\"user\"))\n",
    "        result = await self._model_client.create(self._chat_history)\n",
    "        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n",
    "        self._chat_history.append(AssistantMessage(content=result.content, source=\"assistant\"))\n",
    "        await self.publish_message(Message(text=result.content), DefaultTopicId())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a single-threaded agent runtime and send a message to agent\n",
    "\n",
    "### What is a single-threaded agent runtime?\n",
    "A single-threaded agent runtime is a simple agent runtime that runs all agents in the memory, under same process and thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "Hello World Geeno! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Create an local embedded runtime.\n",
    "import os;\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await Assistant.register(\n",
    "        runtime,\n",
    "        \"assistant\",\n",
    "        lambda: Assistant(\n",
    "            OpenAIChatCompletionClient(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                # get api key from env:OPENAI_API_KEY\n",
    "                api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Start the runtime and publish a message to the assistant.\n",
    "runtime.start()\n",
    "await runtime.publish_message(\n",
    "    Message(text=\"Hello, I am Geeno\"), DefaultTopicId()\n",
    ")\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have successfully created your first AutoGen Assistant Agent and sent a message to it.\n",
    "\n",
    "## What we have learned so far\n",
    "- Create a simple message data contract\n",
    "- Create an assistant agent\n",
    "- Add a message handler to the agent that processes messages from agent runtime\n",
    "- Create a single-threaded agent runtime\n",
    "- Send a message to the assistant agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
