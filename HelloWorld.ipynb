{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World, AutoGen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "from autogen_core.base import MessageContext\n",
    "from autogen_core.components import DefaultTopicId, RoutedAgent, default_subscription, message_handler\n",
    "from autogen_core.components.code_executor import CodeExecutor, extract_markdown_code_blocks\n",
    "from autogen_core.components.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "import tempfile\n",
    "\n",
    "from autogen_core.application import SingleThreadedAgentRuntime\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Message data class\n",
    "The `Message` class is a simple data class that holds a text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your first AutoGen Assistant Agent\n",
    "\n",
    "The assistant will be invoked when it receives a `Message` from agent runtime. Then it will use LLM to generate a response message and publish it back to the agent runtime.\n",
    "\n",
    "The assistant has `default_subscription`, which means it subscribles to messages with all topics from the agent runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@default_subscription\n",
    "class Assistant(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"An assistant agent.\")\n",
    "        self._model_client = model_client\n",
    "        self._chat_history: List[LLMMessage] = [\n",
    "            SystemMessage(\n",
    "                content=\"\"\"\n",
    "            You are a helpful AI assistant. You greet the user by saying 'Hello World <name>! How can I help you today?'.\n",
    "            \"\"\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        self._chat_history.append(UserMessage(content=message.content, source=\"user\"))\n",
    "        result = await self._model_client.create(self._chat_history)\n",
    "        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n",
    "        self._chat_history.append(AssistantMessage(content=result.content, source=\"assistant\"))  # type: ignore\n",
    "        await self.publish_message(Message(content=result.content), DefaultTopicId())  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create  a single thread agent runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='assistant')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an local embedded runtime.\n",
    "import os;\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await Assistant.register(\n",
    "        runtime,\n",
    "        \"assistant\",\n",
    "        lambda: Assistant(\n",
    "            OpenAIChatCompletionClient(\n",
    "                model=\"gpt-4o\",\n",
    "                # get api key from env:OPENAI_API_KEY\n",
    "                api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            )\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a message to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "Hello World Geeno! How can I help you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyuz\\AppData\\Local\\Temp\\ipykernel_84428\\3394563498.py:17: UserWarning: Resolved model mismatch: gpt-4o-2024-05-13 != gpt-4o-2024-08-06. Model mapping may be incorrect.\n",
      "  result = await self._model_client.create(self._chat_history)\n"
     ]
    }
   ],
   "source": [
    "# Start the runtime and publish a message to the assistant.\n",
    "runtime.start()\n",
    "await runtime.publish_message(\n",
    "    Message(\"Hello, I am Geeno\"), DefaultTopicId()\n",
    ")\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have successfully created your first AutoGen Assistant Agent and sent a message to it.\n",
    "\n",
    "## What we have learned\n",
    "- How to create a simple data class\n",
    "- How to create an AutoGen Assistant Agent\n",
    "- How to create and start an agent runtime\n",
    "- How to register an agent to the agent runtime\n",
    "- How to send a message to an agent runtime and receive a response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
