{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World, AutoGen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyuz\\AppData\\Local\\Temp\\ipykernel_94812\\2535584139.py:17: FutureWarning: OpenAIChatCompletionClient moved to autogen_ext. Please import it from autogen_ext.modelsChatCompletionClient.\n",
      "  from autogen_core.components.models import OpenAIChatCompletionClient\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from typing import List, Optional\n",
    "from autogen_core.base import MessageContext\n",
    "from autogen_core.components import DefaultTopicId, RoutedAgent, default_subscription, message_handler\n",
    "from autogen_core.components.code_executor import CodeExecutor, extract_markdown_code_blocks\n",
    "from autogen_core.components.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "import tempfile\n",
    "from pydantic import BaseModel\n",
    "from autogen_core.application import SingleThreadedAgentRuntime\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Message data class\n",
    "The `Message` class is a simple data class that holds a text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    text: str\n",
    "    source: Optional[str] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your first AutoGen Assistant Agent\n",
    "\n",
    "The assistant will be invoked when it receives a `Message` from agent runtime. Then it will use LLM to generate a response message and publish it back to the agent runtime.\n",
    "\n",
    "The assistant has `default_subscription`, which means it subscribles to messages with all topics from the agent runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@default_subscription\n",
    "class Assistant(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"An assistant agent.\")\n",
    "        self._model_client = model_client\n",
    "        self._chat_history: List[LLMMessage] = [\n",
    "            SystemMessage(\n",
    "                content=\"\"\"\n",
    "            You are a helpful AI assistant. You greet the user by saying 'Hello World <name>! How can I help you today?'.\n",
    "            \"\"\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        self._chat_history.append(UserMessage(content=message.text, source=\"user\"))\n",
    "        result = await self._model_client.create(self._chat_history)\n",
    "        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n",
    "        self._chat_history.append(AssistantMessage(content=result.content, source=\"assistant\"))\n",
    "        await self.publish_message(Message(text=result.content), DefaultTopicId())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a message to agent\n",
    "- Create  a single thread agent runtime\n",
    "- Send a message to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant:\n",
      "Hello World Geeno! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Create an local embedded runtime.\n",
    "import os;\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await Assistant.register(\n",
    "        runtime,\n",
    "        \"assistant\",\n",
    "        lambda: Assistant(\n",
    "            OpenAIChatCompletionClient(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                # get api key from env:OPENAI_API_KEY\n",
    "                api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Start the runtime and publish a message to the assistant.\n",
    "runtime.start()\n",
    "await runtime.publish_message(\n",
    "    Message(text=\"Hello, I am Geeno\"), DefaultTopicId()\n",
    ")\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have successfully created your first AutoGen Assistant Agent and sent a message to it.\n",
    "\n",
    "## What we have learned\n",
    "- How to create a simple data class\n",
    "- How to create an AutoGen Assistant Agent\n",
    "- How to create and start an agent runtime\n",
    "- How to register an agent to the agent runtime\n",
    "- How to send a message to an agent runtime and receive a response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
